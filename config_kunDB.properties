bootstrapServerAddress = 172.26.0.111:19092,172.26.0.112:19092,172.26.0.113:19092
ZkAddress = 172.26.0.110
kafkaTopic =test.t_ord_1_new

#column数量（包含rowkey）
columnNum = 6

kafkaSecuredMode = 
saslKerberosServiceName = 
principal = 
keytabPath = 

kafkaRefactor = 3
kafkaConsumerTimeOut = 30000
intervalFlushTime = 100

#是否永久执行数据插入
isInsertUnlimited = false

#如果执行有限制的话设置插入的数据量
maxNum = 100000001

#是否开启argo插入数据时的性能计算
startThroughputCalculate = true

#每隔多少条打印一条日志
ThroughputCalculateInterval = 100000

#是否开启限流
isLimiting = false

#限制tps
tps = 1000000

#是否是分区表
isPartition = false

#哪些属性是被分区的（对应属性的index）
partitionIndex = 3

#gg.handler.tdthandler.SaslKerberosServiceName=kafka
#gg.handler.tdthandler.Principal=admin@SGIDCTDH
#gg.handler.tdthandler.KeytabPath=/root/kafka.keytab
#gg.handler.tdthandler.PrincipalStream=admin@SGIDCTDH
#gg.handler.tdthandler.KeytabPathStream=/etc/slipstream2/conf/kafka.keytab

